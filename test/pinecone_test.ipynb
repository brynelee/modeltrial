{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from llama_index import StorageContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "import os\n",
    "\n",
    "# pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "# pinecone_env = os.environ.get(\"PINECONE_ENV\")\n",
    "\n",
    "pinecone_api_key = os.environ['PINECONE_API_KEY']\n",
    "pinecone_env = os.environ['PINECONE_ENV']\n",
    "\n",
    "# init pinecone\n",
    "pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "langchain_module_path = os.path.abspath(os.path.join('../LangChainStudy/'))\n",
    "model_config_path = os.path.abspath(os.path.join('../LangChainStudy/custom_llms/'))\n",
    "sys.path.insert(1, module_path)\n",
    "sys.path.insert(1, langchain_module_path)\n",
    "sys.path.insert(1, model_config_path)\n",
    "\n",
    "from custom_llms import (\n",
    "    ZhipuAIEmbeddings,\n",
    "    Zhipuai_LLM,\n",
    "    load_api\n",
    ")\n",
    "api_key = load_api()\n",
    "model = Zhipuai_LLM(zhipuai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone免费版只能有一个index，下面是第一次创建时使用\n",
    "# pinecone.create_index(\"xdtest1\", dimension=1024, metric=\"cosine\", pod_type=\"p1\") # pinecone.create_index(\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct vector store and customize storage context\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store = PineconeVectorStore(pinecone.Index(\"xdtest1\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents and build index\n",
    "from llama_index import SimpleDirectoryReader, ServiceContext, VectorStoreIndex\n",
    "from llama_index import GPTVectorStoreIndex\n",
    "documents_p = SimpleDirectoryReader('../data/mr_fujino').load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=model, embed_model=ZhipuAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|██████████| 5/5 [00:01<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "index_p = VectorStoreIndex.from_documents(documents_p, service_context=service_context, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index_p.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这段文字是鲁迅以第一人称“我”叙述的一段经历。故事发生在日本，当时鲁迅在日本学习医学。文章开头提到，日本报纸批评一位名叫藤野的不逊之人，但暗地里却早已受到他的影响。接着，鲁迅回忆起一件小事，干事在黑板上写的广告中，末句是“请全数到会勿漏为要”，并在“漏”字旁边加了一个圈，鲁迅当时觉得好笑，但后来意识到这也是在讥讽他。\\n\\n鲁迅将这些事情告诉了藤野先生，并与一些同学一起去责问干事。最后，流言得以消除，但干事却试图收回一封匿名信。鲁迅将这封信退还给他们。\\n\\n接着，鲁迅描述了自己在日本学习期间受到歧视的经历。由于中国是弱国，所以中国人被认为是低能儿。每当考试成绩公布，六十分以上的中国人会被质疑是否靠作弊取得高分。鲁迅在观看一部关于日本战胜俄国的电影时，看到中国人被描绘为间谍并被枪毙，观众们欢呼雀跃，这使鲁迅深感刺耳。\\n\\n在第二学年结束时，鲁迅决定不再学习医学，并告诉藤野先生。虽然藤野先生脸色悲哀，但并未多说什么。为了让藤野先生安心，鲁迅告诉他想去学生物学，因为藤野先生教给他的知识对学生物学也有用。实际上，鲁迅并没有坚决要学生物学，但为了安慰藤野先生，才这样说。\\n\\n在离开仙台前，藤野先生请鲁迅到他家，给他一张写着“惜别”的合影，并希望鲁迅也能送他一张。这段文字展示了鲁迅在日本学习期间所遭受的歧视以及与藤野先生的真挚感情。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"下面鲁迅先生以第一人称‘我’写的内容，请你用中文总结一下:\")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
